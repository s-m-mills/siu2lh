<!DOCTYPE html>
<html>
<head>
	<meta name="viewpoint" content="width=device-width, initial-scale=1.0">
	<meta property="og:title" content="#DeleteFacebook"/>
	<meta property="og:url" content="https://siu2lh.com/articles/deletefacebook.html"/>
	<style>
		body {
			background-color: #000000;
		}
		h1 {color: #000000;}
		p {
			color: #FFFFFF;
			font-family: "Georgia";
		}

		a:link {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}
		
		a:visited {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}

		a:hover {
			color: #00FFFF;
			background-color: transparent;
			text-decoration: none;
		}

		.h1_recentangle {
			height: 80px;
			width: 100%;
			background-color: #000000;
			text-align: center;
			justify-content: center;
			align-items: center;
			display: flex;
			margin: 0;
		}

		.post_window {
			height: 80%;
			width: 50%;
			background-color: #000000;
			border: solid 2px #FFFFFF;
			padding: 50px;
			text-align: justify;
			text-justify: inter-word;
			align-items: center;
			display: flex;
			transition: width 0.5s, height 0.5s;
			box-shadow: 0 0 2px #FFFFFF;
		}

		.post_window img {
			max-width: 80%;
			max-height: 80%;
			margin: auto;
			display: block;
			border: solid 5px #FFFFFF;
		}

		.post-title {
			font-weight: bold;
			font-size: 24px;
			font-family: "Georgia";
		}

	</style>
	<title>#DeleteFacebook</title>
	<link rel="icon" type="image/x-icon" href="images/favicon.png">
</head>

<body>
	<div class="h1_recentangle" onclick="history.back()"; return false;>
		<h1>
			<a href="#" onclick="history.back()"; return false;><font color="FF7A7A">.</font></a>
		</h1>
	</div>
	<br>
	<center>

		<div class="post_window">
			<p>
				<span class="post-title">#DeleteFacebook</span>
				<br>
				<br>
				<i>This article was first published in New Political Economy in 2021. It can be found <a href="https://doi.org/10.1080/13563467.2020.1858777">here</a>.</i>
				<br>
				<br>
				<b>Abstract</b>
				<br>
				In March 2018, a series of newpaper articles about the subversive use of the social media platform Facebook during various elections in 2016 were published. These revelations produced a backlash against the platform, which resulted in a popular hashtag, <i>#DeleteFacebook</i>.
				<br>
				<br>
				This article uses the <i>#DeleteFacebook</i> campaign as a case study to analyse the contemporary model of platform capitalism. Furthermore, by introducing emerging literature on data trusts--specifically, the notion of a <i>bottom up data trust</i>--this paper argues the <i>#DeleteFacebook</i> campaign reveals, both in its conception and in its ultimate failure, a desire for an alternative model of platform capitalism.
				<br>
				<br>
				By drawing on the <i>#DeleteFacebook</i> campaign, this article argues that a bottom up data trust designed to empower individual users can resolve many of the initial grievances, and barriers to success, experienced by the campaign.
				<br>
				<br>
				<b>Section 1 - Introduction</b>
				<br>
				In March 2018, a series of newspaper articles about the subversive use of the social media platform Facebook by the psychographics firm Cambridge Analytica were published (<a href="https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election">Cadwalladr and Graham-Harrison, 2018</a>). The firm was able to carry out this activity because they had been able to access, harvest and analyse the data of several million Facebook users. This violated Facebook's terms of service (<a href="https://www.facebook.com/zuck/posts/10104712037900071">Zuckerberg, 2018</a>), but equally the firm had faced few checks, and Facebook was seen as having failed in its due diligence (<a href="https://www.ft.com/content/ad276a38-2c9f-11e8-9b4b-bc4b9f08f381">Kuchler, 2018</a>; <a href="https://www.washingtonpost.com/technology/2018/12/19/dc-attorney-general-sues-facebook-over-alleged-privacy-violations-cambridge-analytica-scandal/">Romm <i>et al</i>., 2018</a>). This led to online criticism of Facebook, culminating in a popular hashtag--<i>#DeleteFacebook</i>.
				<br>
				<br>
				This article uses the <i>#DeleteFacebook</i> incident as an interesting case study into the dynamics of contemporary platform capitalism--focused <i>specifically</i> on the platform model utilised by Facebook--as well as emerging conceptus of digital economy that seek to respond to perceived problems within contemporary platform capitalism. Specifically, this article considers how data trusts may be necessary to construct a new model of platform capitalism that offers recourse for the structural tensions which--it is argued here--the <i>#DeleteFacebook</i> campaign is a product of. More specifically still, this article focuses on a type of data trust known as a <i>bottom up data trust</i> (<a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>), proposed to empower individual users by offering a means of collectivising users and giving them a voice. Through an analysis of the <i>#DeleteFacebook</i> campaign, several factors contributing to the campaign's ultimate lack of success are identified. Explanations for how a bottom up data trust can resolve these hindering factors are also offered.
				<br>
				<br>
				The structure of this article is as follows. Section two introduces the conceptial of a digital platform and discusses features of contemporary platform capitalism. Broadly, four features are identified: (1) platforms exist as intermediaries between users; (2) users engage in a barter-like agreement with platforms, receiving platform-services for no monetary costs, but consenting to platform surveillance and advertising; (3) personal data which are 'exchanged' in this barter relationship consist of a transparent component, usually necessary for platform functionality, and an opaque or invisible component, usually used for monetisation; and (4) individual users exercise limited power, accepting the platform's terms of service or forgoing those services entirely.
				<br>
				<br>
				Section three introduces the concept of a data trust, focusing specifically on <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence's (2019)</a> concept of the bottom-up data trust (BUDT). Data trusts are a developing area within the digital economy literature which propose to change how data are controlled and accessed. In contrast to previous data trust conceptions which have focused on connecting platforms (<a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>., 2019</a>), the BUDT is offered by <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence's (2019)</a> as a legal entity to coordinate and protect the interests of individual users.
				<br>
				<br>
				Section four analyses the actions of the <i>#DeleteFacebook</i> campaign using the understanding established in the previous two sections. This article proposes that attempts taken by individual users to collectivise in opposition to Facebook, as well as the material action undertaken--to <i>delete</i> Facebook--demonstrate some recognition by individual users of power asymmetries between themselves and platforms (e.g., Facebook). This article argues that the <i>#DeleteFacebook</i> campaig need not have manifested as it did--and possibly would have been more successful--had a legal entity such as a BUDT been available to users. The primary contribution of this article, therefore, is to argue the <i>#DeleteFacebook</i> campaign represents an initial backlash to the dominant model of platform capitalism and evidences the need for legal entities such as BUDTs.
				<br>
				<br>
				Section five provides a brief evaluation of the success of the <i>#DeleteFacebook</i> campaign, ultimately concluding that the campaign was ineffective. Disucssion then turns to why the campaign, from a digital economy perspective, was ineffective. Three reasons are offered: (1) a superplatform effect, raising the costs of deleting Facebook; (2) insufficient quantitative and qualitative network effects, which allowed the platform to withstand the effects of the campaign, while the campaign struggled to maintain momentum; and (3) a lack of coordination via non-platform infrastructure, which meant the campaign was simultaneously participating in the model of platform capitalism it was opposing. This article then proceeds to argue that an entity such as a BUDT could be used to resolve, wholly or partially, each of these barriers.
				<br>
				<br>
				Section six concludes.
				<br>
				<br>
				<b>Section 2 - Contemporary Platform Capitalism</b>
				<br>
				Platform capitalism is often seen as an evolution of the knowledge economy growth model (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>; <a href="https://doi.org/10.1080/13563467.2019.1590326">O'Donovan, 2020a</a>), where 'knowledge become[s] a source of value' (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016, p. 38</a>), which drives economic growth (<a href="https://doi.org/10.1080/13563467.2019.1590326">O'Donovan, 2020a</a>). As <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek (2016)</a> argues, the value of knowledge creates economic incentives for entities to accumulate and control the flow of knowledge--in the form of information and data--throughout the economy. These entities are platforms which:
				<br>
				<br>
				<i>at the most general level...are digital infrastructures that enable two or more groups to interact. They therefore position themselves as intermediaries that bring together different users </i><a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">(p. 43)</a>.<sup>[<a href="deletefacebook-footnotes.html">1</a>]</sup>
				<br>
				<br>
				Platforms profit from their position within the digital economy primarily by charging one or more of the users they connect some fee for that connection (<a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>). A common example of this is advertising (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>), with large platforms charging brands and advertising agencies a fee to advertise to other users of the platform.<sup>[<a href="deletefacebook-footnotes.html">2</a>]</sup> Online advertising can be a significant part of some platform business models. For isntance, 20% of all global advertisement spending in 2016 went to either Facebook or Google (<a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>), and for these platforms, advertising continues to make up a significant proportion of their revenue. This is especially true of Facebook (see Figure 1).
				<br>
				<br>
				<b>Figure 1. Comparative advertising revenue as a percentage of total revenue for Facebook, Google (Alphabet) and Twitter. Calculations are author's own.</b>
				<br>
				<br>
				<img src="images/deletefacebook-fig1.jpg">
				<br>
				<br>
				If platforms generate revenue from their intermediary position of connecting users, and some users (e.g., brands, advertisers; hereinafter <i>corporate users</i>) generate revenue from advertising to other users (hereinafter <i>individual users</i>), what is the worthwhile return to individual users from their platform activity. A common answer centes on the notion of <i>barter</i>.
				<br>
				<br>
				Platforms are often said to access individual data via a 'barter' (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017, p. 126</a>; <a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014, p. 200</a>) model of exchange with individual users. According to <a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck (2014, p. 200)</a>, the barter model suggests '[individual] users provide personal information to companies [platforms] and receive services in return.' Individual users generally accept this barter arrangement, and often agree to hand over additional information on the premise that more information will allow platform providers to improve functionality of the platform service (<a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014, p. 200</a>; <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>).
				<br>
				<br>
				However, this account is likely too simple. By distinguishing between data and <i>meta</i>data--information about data--<a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck (2014)</a> argues platforms are able to extract additional value from user data which is not consciously synthesised by individual users in the barter arrangement. With specific attention given to social media companies, <a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck (2014, p. 200-201)</a> argues that platforms transform individual user data into metadata:
				<br>
				<br>
				<i>a kind of invisible asset, processed mostly separate from its original context and outside of people's awareness. Social media companies monetize metadata by repackaging and selling them to advertisers or data companies.</i>
				<br>
				<br>
				In their discussion of Facebook, <a href="https://doi.org/10.14763/2020.3.1488 ">Öhman and Aggarwal (2020, p. 7)</a> re-emphasise the invisibility of this part of the barter formulation: '[individual] users will likely not even be aware of the <i>possibility</i> of being profiled.'
				<br>
				<br>
				<a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff (2019)</a> has developed a similar argument to <a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck's (2014)</a> 'metadata' discussion with their concept of 'behavioural surplus' (<a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019, p. 97</a>). <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff (2019)</a> argues that individual users often provide data for functionality purposes (the 'original context' see <a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014, p. 200-201</a>), with the expectation of receiving various services for free. Once platforms have provided these services and achieved a minimum standard of functionality, these companies can then extract further value from data by predicting future behaviours (behavioural surplus) which can be used for profitable activities, such as the sale of these insights to corporate users in the form of targeted advertising services.
				<br>
				<br>
				<a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff (2019)</a> emphasises that platform profitability is derived mostly from the behavioural surplus or metadata component of the barter arrangement and notes that behavioural surplus can at times be desirable. For instance, insofar as it is assumed individual users must see some advertising, the use of metadata to target advertisements may be views as an activity which benefits the corporate user, the individual user and the platform intermediary.
				<br>
				<br>
				However, as <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff (2019)</a> also accepts, the opaqueness or invisibility of the metadata component of the barter arrangement can lead platforms to engage in activities which, if individual users were consciously aware of, they may reject.<sup>[<a href="deletefacebook-footnotes.html">3</a>]</sup> Furthermore, <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> have argued that opaqueness of many data-use practices by platforms leave individual users extremely vulnerable to harm by these platforms (which may provide an ethical basis for imposing data stewardshup obligations on platforms, though as <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> note, does not equate to a <i>legal</i> obligation). Such a capacity to encroach on individual users in this manner has been described by <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 3)</a> as a 'death by a thousand cuts.'
				<br>
				<br>
				Opaqueness gives platforms a first-mover advantage over individual users (see, for instance, two slogans which have become synonymous with big tech and Silicon Valley: 'move fast and break things' and 'it is better to ask for forgiveness than permission') in the barter arrangement which occurs whenever an individual user uses a platform or is connected with a corporate user. A more significant factor, however, is the limited power of inddividual users to negotiate terms with platforms (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>; <a href="https://hbr.org/2019/03/a-new-digital-social-contract-is-coming-for-silicon-valley">Ghosh, 2019</a>). <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 4)</a> describe this problem emerging as a result of a 'power asymmetry' between individual users and platforms. Broadly, two explanations for the presence of this asymmetry can be found.
				<br>
				<br>
				Firstly, the intermediary position of the platform means the platform, in many instances, is necessary to connect individual users. Individual users, therefore, who seek to collectivise in order to demand a better negotiated settlement with the platform<sup>[<a href="deletefacebook-footnotes.html">4</a>]</sup> often--and increasingly (<a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>)--do so <i>via a platform</i>.
				<br>
				<br>
				Secondly, platforms often unilaterally control information which is important to individual users. For instance, <a href="The informational nature of personal identity">Floridi (2011)</a> argues that personal data, and our online identities, are important components of our self-identity. <a href="https://doi.org/10.14763/2020.3.1488 ">Öhman and Aggarwal (2020)</a> also explore this idea, noting that legislation which is designed to give individual users control of their data is often inadequate because platform infrastructures blur the line between an individual's <i>technical</i> data and the data that individuals perceive to be representative of them. As <a href="https://doi.org/10.14763/2020.3.1488 ">Öhman and Aggarwal (2020, p. 7)</a> note, the former is often much less than the latter. All of this is to say, even if one entertains the notion of the barter arrangement between an individual user and a platform, one often cannot entertain the notion of power <i>equality</i> as the latter acts as a gatekeeper to information in the form of data and connection which are of great (if indeed quantifiable) value to the individual user.
				<br>
				<br>
				Where an individual user is dissatisfied or aggrieved with the barter arrangement, 'individuals... are rarely in a position to bargain' (<a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019, p. 4</a>). The options available to individual users, which is to say the extent of individual user agency in this regard, is often to accept the demands of the platform, or to forgo any access to the platform's services (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://hbr.org/2019/03/a-new-digital-social-contract-is-coming-for-silicon-valley">Ghosh, 2019</a>). Returning to <a href="The informational nature of personal identity">Floridi (2011)</a>, one many make a positive case for this--if personal data is a source of self-identity, controlling access to one's personal data (even via <i>denial of access</i>) may still be a means of self-actualisation. But this is an argument that necessarily ignore's the wider, practical picture of the digital economy: in many instances, such as work, individuals must be able to access platform services. <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 2)</a> summarise this state of affairs as thus: 
				<br>
				<br>
				<i>our levers of control are currently limited: at times we can turn the lever to on or off. At others, the lever seems out of reach entirely.</i>
				<br>
				<br>
				In sum, contemporary platform capitalism in relation to individual users can be understood as consisting of four features.<sup>[<a href="deletefacebook-footnotes.html">5</a>]</sup> Firstly, platforms exist as intermediaries, generative revenue by connecting corporate users to individual users (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>; <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>). Secondly, individual users engage with platforms such as social media companies through a barter arrangement, whereby data are exchanged for platform services (<a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014</a>; <a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>). Thirdly, these data consist of a transparent component--often used for functionality--and an opaque component--often the primary source of revenue--with the latter creating vulnerabilities for the individual users (<a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014</a>; <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>). Fourthly, power asymmetries between platforms and individual users arise because of the platform's position within the platform economy, limiting the agency of individual users, in many instances, to one of two options: accept the terms dictated, or reject all of the services provided by the platform (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>; <a href="https://hbr.org/2019/03/a-new-digital-social-contract-is-coming-for-silicon-valley">Ghosh, 2019</a>).
				<br>
				<br>
				<b>Section 3 - Bottom Up Data Trusts</b>
				<br>
				The contemporary model of platform capitalism described in Section2 has increasingly been met with criticism (<a href="https://www.ippr.org/files/2018-08/cej-platformssept18.pdf">Lawrence and Laybourn-Langton, 2018</a>; <a href="http://autonomy.work/wp-content/uploads/2018/05/Nick-Christine-Social-wealth.pdf">Srnicek, 2018</a>; <a href="https://hackermanifesto.org/en/english/">Wark, 2004</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>). <a href="http://autonomy.work/wp-content/uploads/2018/05/Nick-Christine-Social-wealth.pdf">Srnicek (2018, p. 2)</a>, for instance, writes:
				<br>
				<br>
				<i>The biggest companies in the world (measured by market capitalisation) are all increasingly platform companies, while their founders often rank among the wealthiest individuals... All of these companies, in turn, rely to a significant degree upon our data to make their businesses work - yet the sources of that data see no remuneration, even as society mops up and pays for the negative externalities created by these companies.</i>
				<br>
				<br>
				Such criticism has sparked discussion into alternative models of data ownership, with a prominent proposal being that of a data trust (<a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/652097/Growing_the_artificial_intelligence_industry_in_the_UK.pdf">Hall and Pesenti, 2017</a>; <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>; <a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>., 2019</a>; <a href="https://eprints.soton.ac.uk/428276/1/WSI_White_Paper_1.pdf">O'Hara, 2019</a>), though what exactly this means remains somewhat unclear.
				<br>
				<br>
				<a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>. (2019, p. 6)</a> defines a data trust as, 'a legel structure that provides independent stewardship of data.' Under this definition, a data trust exists as a separate legal entity, with clear obligations regarding how data should be treated, and regarding who should have <i>access</i> to data. This idea builds from <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/652097/Growing_the_artificial_intelligence_industry_in_the_UK.pdf">Hall and Pesenti (2017, p. 4)</a>, who define data trusts as, 'proven and trusted frameworks and agreements [which] ensure exchanges [of data] are secure and mutually beneficial.' Note, however, that this definition says nothing of the legal status of a data trust. <a href="https://eprints.soton.ac.uk/428276/1/WSI_White_Paper_1.pdf">O'Hara (2019)</a> has argued that data trusts need not resemble <i>legal</i> trusts--though they could--instead choosing to emphasise the need for a data trust to be flexible to meet needs which arise within specific contexts.
				<br>
				<br>
				By contrast, <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> are quite explicit in their proposal of a data trust, arguing that data trusts should be legal entities, or underpinned by a legal mechanism and obligation. <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 7)</a> are even directly critical of <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/652097/Growing_the_artificial_intelligence_industry_in_the_UK.pdf">Hall and Pesenti (2017)</a> on this topic, writing 'it is unclear what, if anything, such frameworks [proposed by Hall and Pesenti] have in common with legal trust structures.' In regards to the legal nature of a data trust, therefore, <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> are congruent with <a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>. (2019)</a>.
				<br>
				<br>
				This is hardly a clear picture of what, beyond a legal subject matter, a data trust <i>actually</i> is. To reveal this nuance, it is helpful to draw on the language of platform capitalism, where a platform--following <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek (2016)</a>--is an intermediary that connects users. Using this relational picture of platforms and users within the digital economy, <a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>. (2019)</a> propose a data trust which seems to connect <i>platforms</i>, allowing platforms to pool data resources to--in turn--achieve greater data-insights (i.e., behavioural surplus; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>). This proposed data trust, therefore, says little in regard to individual users or tangential data subjects (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://doi.org/10.14763/2020.3.1488 ">Öhman and Aggarwal, 2020</a>). To an extent, this is not surprising--both <a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>. (2019)</a>  and <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/652097/Growing_the_artificial_intelligence_industry_in_the_UK.pdf">Hall and Pesenti (2017)</a> propose a data trust model as a method of encouraging growth in the UK's artificial intelligence (AI) industry; a model with marries the commercial success of private technology firms with the industrial strategy of the state.
				<br>
				<br>
				Despite sharing a grounding in the legal sense, <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> proposed <i>bottom up data trust</i> (BUDT hereinafter) responds primarily to the relational nature of the barter model of platform capitalism, with an emphasis on power relations. <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 4-5)</a> write:
				<br>
				<br>
				<i>[T]here is a power-asymmetry between [data] subjects and [data] controllers [within contemporary platform capitalism]. This asymmetry arises because the controllers have accumulated data from many individuals, which allows them to invest time and expertise into the processing [of data]. In contrast, the subject has knowingly or unknowingly provided her data to many entities - including most "invisible" data brokers - and has neither the expertise nor the time to unpick each controller's motivations and methods... The legal mechanism of a data trust aims to leverage the resource concomitant with the pooling of data to directly address the power-asymmetries.</i>
				<br>
				<br>
				The BUDT is proposed as a legal entity which aims to empower individual users in their interactions with platforms. One could interpret this in the language of class and unionisation (<a href="https://hackermanifesto.org/en/english/">Wark, 2004</a>; <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>), with individual users collectivising and entrusting the BUDT to negotiate on their behalf with the platform, or more plainly as the BUDT acting as a route--alternate from that of a platform--for individual users to connect (but importantly, the BUDT does not provide the same platform services, and therefore does not <i>displace</i> the platform). This is a discussion <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019, p. 7)</a> entertain:
				<br>
				<br>
				<i>[T]he collective setting of terms by the [bottom up data] trust is a way for data subjects [individual users] to pool their rights to acquire a 'voice'... There are many historical precedents for the formation of such bodies to empower the disenfranchised. For example, 'Land Societies' were formed almost two centuries ago for the purpose of giving a political voice to their members, who would not otherwise have had the resoures to acquire the freehold land conditioning their right to vote.</i>
				<br>
				<br>
				The exact nature (beyond as a legal entity) and responsibility of a BUDT remains somewhat undefined,<sup>[<a href="deletefacebook-footnotes.html">6</a>]</sup> and returns to discussions given by both <a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>. (2019)</a> and <a href="https://eprints.soton.ac.uk/428276/1/WSI_White_Paper_1.pdf">O'Hara (2019)</a> regarding the importance of flexibility and context in data trust design. But the relational impact within the digital economy remains clear: the BUDT exists in between an individual user and the platform, and exists--in accordance with its legal underpinnings--to empower the individual user in their interactions with the platfrom. The result of this empowerment, <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> suggest, would be to rectify the imbalance, and thus alter, the barter arrangement between individual users and platforms.
				<br>
				<br>
				<b>Table 1. The interaction of contemporary platform capitalism and the bottom up data trust</b>
				<br>
				<br>
				<img src="images/deletefacebook-tab1.jpg">
				<br>
				<br>
				Having established in the previous section (Section 2) some relevant features of contemporary platform capitalism, and in this section (Section 3) the concept of a BUDT and how this concept interacts with these contemporary features (see Table 1), attention now turns to the case of the <i>#DeleteFacebook</i> campaign. Section 4 describes the campaign in brief, focusing on how the shape of the campaign can be understood via the already identified features of contemporary platform capitalsm. Section 5 then examines how the campaign failed to affect change, and how these failings could be both resolved by, and reveal the relevance of, an entity like a BUDT.
				<br>
				<br>
				<b>Section 4 - <i>#DeleteFacebook</i></b>
				<br>
				The hashtag, <i>#DeleteFacebook</i>, began trending on social media platforms--particularly Twitter--following revelations in March 2018 regarding the use of individual user Facebook data by the psychographics firm Cambridge Analytica (<a href="https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election">Cadwalladr and Graham-Harrison, 2018</a>). According to <a href="https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election">Cadwalladr and Graham-Harrison (2018)</a>, Cambridge Analytica improperly accessed the data of some 50 million Facebook users, which were then used as part of targeted political advertising campaigns on the Facebook platform, including during the 2016 U.S. presidential election. While much attention was paid to Cambridge Analytica following these revelations, the scandal also revealed the failings of Facebook to protect user data, hence the hashtag <i>#DeleteFacebook</i> (<a href="https://www.ft.com/content/97ecf7ce-2e8d-11e8-9b4b-bc4b9f08f381">Thomas, 2018</a>).
				<br>
				<br>
				Considering the <i>#DeleteFacebook</i> movement as a response to contemporary platform capitalism, the first feature is satisfied--individual users interacted with the Facebook platform, which itself served as an intermediary between users, both individual users and corporate users. Attention immediately turns to the second feature, therefore, that of a barter arrangement.
				<br>
				<br>
				Individual users did, in 2018 and onwards, interact with Facebook via a model of barter which has been described by <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>. (2018)</a> and <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff (2019)</a>, namely users exchange their data and in turn receive access to the Facebook platform. The apparent outrage at Facebook's failure to protect user data, which culminated in the hashtag, reveals evidence that individual users were aware--at least <i>in part</i>--of a barter-like arrangement with the platform. At the same time, such a proposition presents an issue, namely that if the relationship between platform and individual user were a genuine barter relationship, one would not expect the latter to be outraged when the former utilises that which the two trade in a way the latter dislikes after the exchange has occurred.
				<br>
				<br>
				Borrowing a term from <a href="https://warwick.ac.uk/fac/arts/english/currentstudents/undergraduate/modules/fulllist/special/statesofdamage/syllabus201516/graeber-debt_the_first_5000_years.pdf">Graever (2011)</a>, the notion of a <i>human economy</i> may offer a solution. Broadly, a human economy is one where the exchange of goods and services follows social norms, standards and expectations, and not one of value as expressed in money-economies.<sup>[<a href="deletefacebook-footnotes.html">7</a>]</sup> If the interaction between an individual user and the Facebook platform is viewed through the lens of a human economy--a proposition with seems reasonable given the lack of explicit reference to money and an emphasise on the <i>social</i> and <i>connection</i>--the outrage an individual user may feel when their bartered data is musused by Facebook becomes understadable: the exchange was made with an <i>implicit expectation</i> of reasonable treatment.
				<br>
				<br>
				This is also very close to Floridi's (2011) conception of the digital-self: if our digital selves are part of, or perhaps an <i>extension</i> of, ourselves, then the haphazard treatment of individual user data can be interpreted as an act of disresepct or haphazard treatment of <i>people</i>.<sup>[<a href="deletefacebook-footnotes.html">8</a>]</sup> <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>. (2018, p. 2)</a> have also mused in this area of platforms disrupting social fabrics, first writing, 'Platforms do not reflect the social: they <i>produce</i> the social structures we live in', before later elaborating on the issues this creates: '[in] upend[ing] established institutional arrangements... [platforms] put traditional values under pressure' (<a href="https://academic.oup.com/book/12378?login=false">p. 32</a>). Ultimately, what this analysis arrives at is an idea which has already been briefly mentioned, and which is prominent in the data trust literature, that of <i>data stewardship</i>. Data stewardship, in brief, can be understood as simultaneously placed on a data controller (e.g., a platform or a data trust) due to their control of data, and the expectations of the data controller by the data subejct (e.g., individual users) when data are provided (<a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a> ;<a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>., 2019</a>).
				<br>
				<br>
				As such, the <i>#DeleteFacebook</i> campaign can be understood as a product of tensions which arise between a barter model of exchange on the part of the Facebook paltform, and a human economy, <i>stewardship</i> perspective on the part of individual users.
				<br>
				<br>
				An alternative explanation for the campaign might come from the third feature of platform capitalism identified here, that being behavioural surplus or the visible nature of <i>functional</i> data and the invisible nature of <i>revenue-generating</i> data (<a href="https://pdfs.semanticscholar.org/6d1c/5eb45a50d62c031088bc4b82828d582068a4.pdf">van Dijck, 2014</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>). Starting with this feature, it is possible to assume that the barter conception of contemporary platform capitalism is correct and not entertain the idea of human economies. Doing so, insofar as individual users exchange only that which is immediately visible to them--which is to say, the data which is necessary for platform functionality--revelations from the Cambridge Analytica scandal may have also revealed--for some, for the first time <a href="https://doi.org/10.14763/2020.3.1488 ">(Öhman and Aggarwal, 2020)</a>--the extent to which Facebook was also extracting <i>invisible data</i>, and generating value (i.e., behavioural surplus) from these additional, invisible data. Under a barter model, an individual user could therefore determine that they have been ripped off in their arrangement with the platform, and express outrage as a result. The behaviour of deletion would not be so unexpected, either; it has long been known that, when faced with situations perceived to be unfair, people will punish those acting unfairly, even if it results in a cost to themselves (<a href="https://www.jstor.org/stable/1806070">Kahneman <i>et al</i>., 1986a</a>, <a href="https://www.jstor.org/stable/2352761?item_view=read_online">1986b</a>).
				<br>
				<br>
				Again, and this time without a major theoretical adjustment in outlook, a feature of platform capitalism--invisible data and behavioural surplus--can be used to explain the emergence of the <i>#DeleteFacebook</i> campaign.
				<br>
				<br>
				The final identified feature of contemporary platform capitalism--that of limited individual user power--completes this analysis. Following this feature, individual users--acting as individuals--have limited power and are faced with an ultimatum to either accept the terms of services dictated by the platform, or to reject the terms and thus not have access to the platform at all. The manifestation of this feature of contemporary platform capitalism is quite striking and most obvious. Consider, simply, the name of the campaign: <i>#DeleteFacebook</i>. The decision by individual users to coalesce around a hashtag advocating for the <i>deletion</i> of Facebook, rather than, say, the <i>reformation</i> or <i>restructure</i> of Facebook, is demonstrative of the limited capacity for objection to platform behaviour which individual users have within contemporary platform capitalism (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://hbr.org/2019/03/a-new-digital-social-contract-is-coming-for-silicon-valley">Ghosh, 2019</a>). Furthermore, the choice of a hashtag as a protest vehicle is also telling; the choice to collectivise around a hashtag would seem to support the observation offered by <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> that individual users, operating as individuals within contemporary platform capitalism, lack a voice and a strong means of recourse. The hashtag, therefore, reveals both the need to collectivise actions for action to be effective<sup>[<a href="deletefacebook-footnotes.html">9</a>]</sup> and the limited means of collectivising which individual users have, means which are still reliant on contemporary platform capitalist infrastructure.
				<br>
				<br>
				<b>Section 5 - Discussion</b>
				<br>
				In any analysis, it is necessary to offer some conclusion as to the effect or <i>effectiveness</i> of the matter at hand. An attempt at this is made here, regarding the success or failure of the <i>#DeleteFacebook</i> campaign, though this is not aided by the lack of revealed criteria through which to judge success. This is, in itself, a failing of the campaign: a lack of clear communication of the campaign's objectives. In absence of such clarity, the most productive means of evaluating the success or failure is to take a literal approach: did the <i>#DeleteFacebook</i> campaign succeed in getting individual users to delete their Facebook accounts? In the first part of this section, data are presented to provide an answer to this question.
				<br>
				<br>
				For ease, this section is split into three parts. As mentioned, the first subsection evaluates the success or failure of the <i>#DeleteFacebook</i> campaign. Ultimately determing the campaign was not successful at affecting change, the second subsection offers several reasons as to why this may have been the case, drawing once more on the features of contemporary platform capitalism previously discussed. The final subsection considers how a BUDT could resolve, wholly or partially, these identified difficulties, and argues that the failure of the <i>#DeleteFacebook</i> campaign makes a compelling case for the introduction of BUDTs.
				<br>
				<br>
				<b><i>Section 5.1 - The Success or Failure of the #DeleteFacebook Campaign</i></b>
				<br>
				The discussion begins with the question: did the <i>#DeleteFacebook</i> campaign succeed in encouraging individual Facebook users to delete their Facebook accounts? <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/45290cc0-656d-4a88-a2f3-147c8de86506.pdf">Facebook (2019</a>, <a href="https://s21.q4cdn.com/399680738/files/doc_financials/annual_reports/2018-Annual-Report.pdf">2018</a>) report the number of Facebook users, to the nearest million, in their quarterly reports. As would be expected, the company also reports revenue per user, which is also a potential indicator of the impact of the campaign given Facebook's revnue model is dependent on user numbers.
				<br>
				<br>
				An analysis of the Facebook user data would suggest the campaign was not successful; following the <i>#DeleteFacebook</i> campaign (Q1'18), Facebook did not see a noticeable decrease in user numbers (see Figure 2).
				<br>
				<br>
				<b>Figure 2. Daily and Monthly Active Facebook users, and estimated counterfactuals, with Q1'18 indicating the start of the <i>#DeleteFacebook</i> campaign. Figures are reported by Facebook, estimates are author's open, based on a linear extrapolation.</b>
				<br>
				<br>
				<img src="images/deletefacebook-fig2.jpg">
				<br>
				<br>
				The company did, however, see a slight fall in the user growth-rate, based on a linear extrapolation from Q1'18, which <i>may</i> be attributed to the campaign. However, it seems unwise to attribute this finding with any confidence to the <i>#DeleteFacebook</i> campaign. Firstly, a reduction in growth is not equivalent to a deletion of accounts and is therefore neither congruent with the assumed aims of the campaign nor unexplainable by alternative factors, such as a reduction in the platform's popularity. Secondly, and by way of an alternative factor, a slight decline in growth was not unexpected by Facebook due to market saturation. Writing in 2018, <a href="https://s21.q4cdn.com/399680738/files/doc_financials/annual_reports/2018-Annual-Report.pdf">Facebook (2018, p. 8)</a> state, 'we anticipate that our active user growth rate will generally decline over time as the size of our active user base increases.'
				<br>
				<br>
				Additionally, one can say with markedly more confidence that the campaign <i>did not</i> significantly impact Facebook, as the company has by happenstance <i>already</i> experienced a fall in the user growth-rate between Q3'17 and Q4'17--a quarter <i>prior</i> to the campaign. Indeed, this pattern is better explained by market saturation than by a successful campaign to dissuade Facebook users from continuing to use the platform.
				<br>
				<br>
				Two caveats to this conclusion are (a) any reduction in users may adversely impact Facebook's ability to lever network effects in the future (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>), and so the impact of <i>#DeleteFacebook</i> may be more long-term than current data can capture; and (b) Facebook only report <i>active</i> users, and so it is not possible to tell how many <i>absolute</i> Facebook users the company had before and after the campaign. These caveats are worthy of some consideration, with the impact of network effects being discussed in more detail below. At present, it is simply worth stating that any attempt to estimate the impact of <i>#DeleteFacebook</i> based on future growth-rates and diminished network effects is likely to be highly inaccurate as aforementioned additional factors such as popularity, competition and saturation culd also account for a reduced growth rate.
				<br>
				<br>
				On the question of absolute users, it is reasonable to hypothesise that some inactive Facebook users would respond to the <i>#DeleteFacebook</i> campaign, and further, inactive users may have been more inclined to delete their accounts as their inactivity would suggest a reduced stake in the platform. However, by the same logic that supposes inactive users may be more disposed to deleting their accounts, inactivity may also mean they are less likely to engage in or have sympathies with the <i>#DeleteFacebook</i> campaign. In absence of data, the impact of inactive users can only be speculated.
				<br>
				<br>
				The conclusions drawn from Figure 2 – that the campaign had no apparent effect – are also drawn from Figure 3, which shows revenue per user each quarter.
				<br>
				<br>
				<b>Figure 3. Average advertising revenue per Facebook user (worldwide), with Q1'18 indicating the start of the <i>#DeleteFacebook</i> campaign. Figures are as reported by Facebook.</b>
				<br>
				<br>
				<img src="images/deletefacebook-fig3.jpg">
				<br>
				<br>
				While Facebook regularly sees declines in average revenue per user, these are part of an apparent seasonal trend, with the highest revenue in each year coming in Q4, and the lowest in Q1. Despite this seasonality, Facebook’s average revenue per user has been on an increasing trend, nearly doubling in around 3 years from 2017 to 2019. What is most compelling for the present discussion, however, is the absence of any notable impact from the <i>#DeleteFacebook</i> campaign in Q1’18. These data reinforce the broad conclusion presented previously: the <i>#DeleteFacebook</i> campaign does not appear to have succeeded in impacting Facebook on a user level, either in terms of active users or revenue per user.
				<br>
				<br>
				<b><i>Section 5.2 - Barriers to Success</i></b>
				<br>
				The barriers for the success of the #DeleteFacebook campaign are numerous, and several likely have little to do with platform capitalism. For instance, it may well be that the underlying grievance which produced the campaign – mistreatment of individual user data – was not so serious an issue as to galvanise the support of a critical mass. As previously discussed, the source of such a grievance within contemporary platform capitalism is complex, and there is no reason to believe the perspective amongst Facebook users is homogeneous.
				<br>
				<br>
				However, several reasons why the campaign may not have been successful can be drawn from contemporary platform capitalism. This article offers three: superplatform effects; network effects; and an absence of sufficient infrastructure.
				<br>
				<br>
				<b><i>Superplatform Effects</i></b>
				<br>
				The term 'superplatform' (<a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018, p. 16</a>) is one coined by <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>. (2018)</a> in response to <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz's (2017, p. 376)</a> concept of 'platform logic,' though these concepts should not be used interchangeably. The platform logic model developed by <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz (2017)</a> expands on the definition of platforms as intermediaries given by <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek (2016)</a>. <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz (2017, p. 378)</a> argues that platforms can exist not merely as intermediaries between users, but also as intermediaries between other platforms, with platform logic refering, 'to the interplay between different mechanics inherent to digitial platforms.' This allows <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz (2017, p. 378)</a> to distinguish, 'between different conceptual and topological levels: micro, meso, and macro' within contemporary platform capitalism, and as such differentiate platforms based on their ability to control the flow of data between users and the platform (micro); their ability to establish interconnections between platforms and users (meso); and their ability to extract value from their position within the platform ecosystem (macro; <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz, 2017</a>).
				<br>
				<br>
				In their work on what they call the 'platform society,' <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>. (2018, p. 2)</a> focus on <a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz's (2017)</a> macro-level platform. They expand on the idea of the macro-level platform by proposing, 'infrastructural platforms' which, 'form the heart of the ecosystem upon which many other platforms and apps can be built' and distinguishing these from micro- and meso-level 'sectoral platforms' which 'serve a particular sector or niche' (p. 12-13). The 'superplatform' is thus defined in terms of an infrastructural platform: 'infrastructural platforms function more or less as utilities or 'superplatforms' because they provide crucial basic information services upon which other sectoral platforms can be stacked or built' (p. 16). <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>. (2018)</a> offer Google's Maps service as an example of a superplatform (and indeed, Google itself) as the Maps function is often embedded within and crucial to the functionality of many sectoral platforms, such as the ride-hailing platform Uber.
				<br>
				<br>
				Facebook is another example of a superplatform (<a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>). Facebook provides functionality to several additional platforms, and owns several more in turn. For instance, the populat instant messaging app Messenger is owned by Facebook and allows individual users to communicate to one another via their Facebook accounts without having to directly access the Facebook platform (<a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/45290cc0-656d-4a88-a2f3-147c8de86506.pdf">Facebook, 2019</a>). Facebook has also sort to establish its 'Like' and 'Share' plug-ins on various third-party websites (<a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>), offering these third-parties valuable data insights while furthering Facebook's own 'corporate accumulation' (<a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz, 2017, p. 379</a>) in accordance with the macro-level of platform logic (<a href="https://doi.org/10.1002/poi3.159">Andersson-Schwarz, 2017</a>) and platform capitalism (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862"> Srnicek, 2016</a>; <a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>). Finally, in several developing countries, Facebook has positioned itself as a portal to the wider internet, if not acting as <i>the internet itself</i> (<a href="https://doi.org/10.14763/2020.3.1488 ">Öhman and Aggarwal, 2020</a>). Even where the reliance on Facebook is not quite so great, using one's Facebook account to sign up or create accounts with various websites across the internet has become a near ubiquitous feature (<a href="https://www.hbs.edu/faculty/Pages/item.aspx?num=56791">Zuboff, 2019</a>), in turn elevating the importance of Facebook for individaul users of <i>non-Facebook services</i>.
				<br>
				<br>
				The major consequence of Facebook’s superplatform position in the present discussion is that because Facebook provides functionality to several other services, the costs of deleting Facebook for an individual user is not simply that of forgoing the Facebook social network platform, but forgoing any services or functionality which the user also uses which rely on Facebook’s platform infrastructure. The call to <i>#DeleteFacebook</i>, then, may have in reality been a call to delete several other services which users were not willing to forgo.
				<br>
				<br>
				<a href="https://www.nytimes.com/2018/03/21/technology/personaltech/delete-facebook.html">Chen (2018, para. 2)</a> writing in the <i>New York Times</i>, has also argued Facebook’s market position hampered the <i>#DeleteFacebook</i> campaign. They write,
				<br>
				<br>
				<i>while deleting your [Facebook] account is as simple as clicking a few buttons, Facebook may be too ubiquitous to truly quit. For one, it would probably be inaccurate to say you have removed Facebook from your life just by leaving the site. Chances are you still use WhatsApp, the largest messaging app in the world, or Instagram, the most popular photo-sharing app. Facebook owns both.</i>
				<br>
				<br>
				<a href="https://www.nytimes.com/2018/03/21/technology/personaltech/delete-facebook.html">Chen's (2018)</a> discussion reveals a second element of the superplatform consequences of Facebook. Not only might deleting Facebook undermine the functionality of other services an individual user may have wanted to continue to use, but insofar as those other services are owned by Facebook, the platform may still be able to collect data via these sectoral platforms.
				<br>
				<br>
				Superplatform effects and the platform logic of contemporary platform capitalism, therefore, offer two explanations for the failure of the <i>#DeleteFacebook</i> campaign. Firstly, the functionality consequences of deleting Facebook may have been too great, as the platform allows several other sectoral platforms to function, platforms users did not want to forgo. Secondly, the effectiveness of actually deleting Facebook may have been diminished because Facebook would have still been able to collect information on individual users via the several other sectoral platforms with the company owns. Therefore, some individual users may have seen deletion as an ineffective strategy.
				<br>
				<br>
				<b><i>Network Effects</i></b>
				<br>
				Most Facebook users do not use the platform simply for its technical functionality, which is the primary factor involved in superplatform effects, but because the platform offers personal and social advantages which competitors do not. For those who can easily switch to a competitor service, the relative cost of deleting Facebook would seem to be lower than the costs experienced by those who needs are not met by alternative platforms.
				<br>
				<br>
				Distinguishing between the technical functionality of services and what might be called the practical functionality of services, the latter is typically captured using the term network effects (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862"> Srnicek, 2016</a>; <a href="https://academic.oup.com/book/12378?login=false">van Dijck <i>et al</i>., 2018</a>; <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan 2020b</a>). <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan (2020b)</a> provides a succinct definition of network effects, incorporating ideas found within the economic-market literature (<a href="https://idv.sinica.edu.tw/kongpin/teaching/io/KatzShapiro1.pdf">Katz and Shapiro, 1985</a>, <a href="https://faculty.haas.berkeley.edu/shapiro/systems.pdf">1994</a>): ‘Network effects arise when adoption of a particular product, standard or platform by additional users make the product, standard or platform more valuable to all users’ (<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan, 2020b, p. 2</a>). They offer the example of a telephone network, arguing that the value of the network increases as the number of telephone users on the network increases; if only one person has a telephone, that telephone is rather useless to them as a telephone.
				<br>
				<br>
				Yet this definition of a network effect remains mired in economic logic. As <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan (2020b)</a> recognises, while the value of the network does increase with the addition of another user, insofar as the value of a network is actually the value of connections between users, some users will be more valuable to connect with than others (<a href="https://doi.org/10.1002/smj.2013">Afuah, 2013</a>). For instance, a popular celebrity is likely to be a more valuable connection for a fan of that celebrity than a connection with a person whom the individual user knows little about. <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan (2020b, p. 2, original emphasis)</a>, therefore, draws a distinction between what they called, ‘first-order network effects, which involve a quantitative increase in the number of potential connections’, and, ‘second-order network effects, with involve qualitative improvements in the way people are connected.’ The lack of success of the <i>#DeleteFacebook</i> campaign can be considered in terms of first – and second-order network effects.
				<br>
				<br>
				Following the rationale of networks effects, insofar as the addition of an additional user increase the value of the network for all other users, and thus the platform, the strategy behind the <i>#DeleteFacebook</i> campaign may be described as one that supposes the subtraction of an additional user decreases the value of the network for all other users, and thus the platform. This may have two theoretical consequences. Firstly, the loss of value for all users should galvanise more users to leave, as the costs of leaving becomes less than the benefits of leaving. Secondly, the loss of value in the network should translate as a loss of value for the platform, forcing the platform to intervene to halt the network’s loss of value. The failure of the campaign – again, theoretically – <i>could</i> thus be understood as having failed to reach critical mass, at which point it would have been in Facebook’s interests to effectively respond to the movement.
				<br>
				<br>
				In terms of first-order network effects, this lack of critical mass may be explained by the fact that the relative reduction in value by the removal of a single user is very small when the absolute number of users is very large. For the reduction in individual users to become cognizant for those not caught up in the initial <i>#DeleteFacebook</i> wave, the campaign would have had to have produced a significant reduction in the number of users, and thus the value of the network. This is a threshold which would have needed to be satisfied only after first having eliminated the growth-rate in the Facebook user-base (i.e. more people would have had to be deleting their accounts than those who were creating accounts). As the data show, Facebook maintained a positive growth rate throughout the <i>#DeleteFacebook</i> campaign (see Figure 2), suggesting the campaign failed to adversely effect the value of Facebook’s network.
				<br>
				<br>
				In terms of second-order effects, accepting that the network-value of users is different, and some users may be more valuable to the network wholly (e.g. a celebrity) or partially (e.g. a personal friend), the criteria for the <i>#DeleteFacebook</i> campaign to be successful become different. For instance, rather than the campaign simply having to produce a negative growth-rate in the Facebook user-base, the campaign instead needed to decrease the value of <i>connections</i> within the network. While the campaign <i>may</i> have been able to reduce the value Facebook’s network from a first-order, <i>quantitative</i> perspective, the platform itself retained almost all of its key brands, celebrities, and content producers. As such, even if the absolute number of connections available on the Facebook network decreased (which the data suggest it didn’t), the platform was insulated from a loss of value by retaining the means to ensure the <i>quality</i> of the remaining connections (<a href="https://doi.org/10.1002/smj.2013">Afuah, 2013</a>; <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3832876">O’Donovan, 2020b</a>). Evidence for the importance of second-order network effects can be seen when the founder of WhatsApp – a Facebook-owned messaging platform – backed the <i>#DeleteFacebook</i> movement (<a href="https://www.theguardian.com/technology/2018/mar/20/facebook-cambridge-analytica-whatsappdelete">Solon 2018</a>). Despite being only a single connection on the network, the audience and background of the supporter was enough to make headlines (i.e. <a href="https://www.theguardian.com/technology/2018/mar/20/facebook-cambridge-analytica-whatsappdelete">Solon (2018)</a> in <i>The Guardian</i>; <a href="https://www.theverge.com/2018/3/20/17145200/brian-acton-delete-facebook-whatsapp">Newton (2018)</a> in <i>The Verge</i>; <a href="https://www.huffingtonpost.co.uk/entry/whatsapp-founder-brian-acton-delete-facebook_n_5ab1c2fbe4b008c9e5f287ee?ri18n=true&guccounter=1">Bulter (2018)</a> in <i>The Huffington Post</i>).
				<br>
				<br>
				<b><i>Absence of Sufficient Infrastructure</i></b>
				<br>
				The final barrier to success returns to the feature of a platform as an intermediary between different users. One could imagine, for a moment, that the <i>#DeleteFacebook</i> campaign was broadly similar to other online-coordinated protest movements, but this conception appears to be incorrect.
				<br>
				<br>
				Consider <a href="https://ijoc.org/index.php/ijoc/article/view/3963">Gerbaudo’s (2016)</a> work on digital protest movements. One feature <a href="https://ijoc.org/index.php/ijoc/article/view/3963">Gerbaudo (2016, p. 254)</a> highlights is that of ‘digital enthusiasm.’ This concept suggests that a platform infrastructure, which greatly reduces the spatial (i.e. distance between people) and temporal (i.e. time to receive information) distance between members of a movement can lead to a positive feedback effect, amplifying an initial emotive narrative into a larger narrative. For instance, <a href="https://ijoc.org/index.php/ijoc/article/view/3963">Gerbaudo (2016)</a> discusses contemporary protest movements in Egypt and Spain, both of which used social media to coordinate on-the-ground action, and to rapidly <i>communicate</i> these actions as quick wins which generate enthusiasm and motivate others.
				<br>
				<br>
				The #DeleteFacebook campaign would be expected to struggle in producing digital enthusiasm on two counts. Firstly, the act of deleting Facebook is also the loss of a vital channel of communication in building a persuasive narrative and movement. While other platforms could be used to rectify this issue--Twitter was prominent in this regard--this introduces an additional problem, separate from the two immediately being discussed, namely that <i>platform infrastructures are being used to protest platform infrastructures</i>. The second problem is the absence of evidence of action around which a narrative can be built. As <a href="https://ijoc.org/index.php/ijoc/article/view/3963">Gerbaudo (2016)</a> notes, when a town square or building is occupied, or when an act of disobedience is reported, members of the protest movement can feel like their actions have impact, and are thus worthwhile, even if this feeling is vicarious. The <i>#DeleteFacebook</i> campaign was, then, disadvantaged because their actions were against a platform--over which individual users had almost no agency--rather than a government or a physical company--over which individuals can <i>claim agency</i> through action. For instance, Facebook controls the most up-todate data on Facebook user numbers, and so an individual user who deletes their account cannot see, in real-time, the consequences of their actions--a vital source of motivation for others.
				<br>
				<br>
				<b><i>Section 5.3 - The Role of Bottom Up Data Trusts</i></b>
				<br>
				The proposition offered here is that, for each of these identified barriers to success, the use of a BUDT, or BUDT-like entity, could conceivable resolve – either partially or wholly – the issues faced by the <i>#DeleteFacebook</i> campaign. This is not to pass judgement on the efficacy of the campaign. Instead, the position adopted here is that the <i>#DeleteFacebook</i> phenomenon is an interesting case study, from which the dynamics of contemporary platform capitalism and future models of platform capitalism can be understood.
				<br>
				<br>
				A BUDT can resolve the challenge of the superplatform effect insofar as a data trust, at its core, determines who should access data (<a href="https://theodi.org/article/odi-data-trusts-report ">Hardinges <i>et al</i>., 2019</a>). This means that, in principle, a BUDT could deny one sectoral platform, controlled by a superplatform, access to user data, while allowing another sectoral platform controlled by the superplatform access to data. Indeed, a BUDT could simply require a commitment from a superplatform that data and data insights produced by one sectoral subsidiary are not utilised by another subsidiary, or indeed the superplatform itself, without the consent of either the individual user, or the BUDT, depending on the powers granted to the BUDT. Facebook itself has demonstrated its willingness to accede to this demand, at least in principle. For instance, Calibra, the Facebook subsidiary charged with operating the cryptocurrency Libra, has stated, ‘Calibra will not share account information or financial data with Facebook Inc. or any third party without customer consent’ (<a href="https://www.eff.org/files/2019/07/10/calibra-customer-commitment.pdf">Calibra 2019, p. 1</a>).
				<br>
				<br>
				<b>Table 2. Barriers to success and the potential role of a BUDT.</b>
				<br>
				<br>
				<img src="images/deletefacebook-tab2.jpg">
				<br>
				<br>
				If such an approach were adopted more widely, the costs to an individual user of forgoing a single platform would be dramatically reduced, as they would still be able to use the platform services of other associated platforms. A BUDT is well placed as a means of firstly establishing this principle more widely, and secondly regulating this principle in practice.
				<br>
				<br>
				The discussion above highlighted two issues related to network effects. Firstly, by its collectivising nature, the BUDT helps resolve the problem of quantitative network effects, allowing individual users to understand how much influence an action might have on the Facebook network. This very much follows a key principle established by <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence (2019)</a> in relation to the BUDT, namely that individual users lack a voice as individuals, but gain a voice when coordinated. Secondly, by virtue of the legal status of the BUDT, as well as its presumed infrastructural sophistication, the BUDT may serve as a legitimising institution, adding credence to the objections of individual users. This may resolve, to an extent, the problem of qualitative network effects, as the BUDT acts as a highly influential entity within the platform ecosystem.
				<br>
				<br>
				Finally, the existence of a BUDT solves the several infrastructural challenges identified. As an important first principle, the BUDT is positioned as a means for individual users to connect <i>without</i> the need for a platform such as Facebook. In this instance, therefore, the desire to challenge the contemporary platform capitalism model is not undermined by simultaneously perpetuating this model using platform tools such as hashtags, or indeed platforms themselves. Considering <a href="https://ijoc.org/index.php/ijoc/article/view/3963">Gerbaudo’s (2016)</a> digital enthusiasm approach, a BUDT can serve several motivationally important functions which strengthen opposition. The BUDT, for instance, can broadcast information such as the number of individual users it represents, and how this has changed over time. The BUDT can also serve as a forum communicating various successes won by the trust, enabling individual users to experience a sense of vicarious achievement (see Table 2).
				<br>
				<br>
				<b>Section 6 - Conclusion</b>
				<br>
				This article has examined several features dominant within contemporary platform capitalism by considering the case of the <i>#DeleteFacebook</i> campaign. This analysis reveals several areas of structural tension between individual platform users and digital platforms, tensions which suggest an alternative model of platform capitalism may be necessary in the future. In this article, one alternative model which has been considered is that of the bottom up data trust (BUDT), a legal entity which controls a platform’s access to the data of its members (i.e. users) as a means of coordinating individual users and establishing more favourable--or at least more empowering--arrangements with the platform.
				<br>
				<br>
				Using the <i>#DeleteFacebook</i> campaign, this article has argued the outrage at Facebook following the Cambridge Analytica data scandal can be understood in terms of the levers of control available to individual users. Individual users who required the Facebook platform to become connected faced a power asymmetry which manifest as an ultimatum of sorts: accept the terms of service offered by Facebook or forgo the Facebook platform. This issue has been identified previously (<a href="https://doi.org/10.1080/1369118X.2016.1186713">Yeung, 2017</a>; <a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>; <a href="https://hbr.org/2019/03/a-new-digital-social-contract-is-coming-for-silicon-valley">Ghosh, 2019</a>), and is a core motivation for the innovation of the BUDT (<a href="https://doi.org/10.1093/idpl/ipz014">Delacroix and Lawrence, 2019</a>).
			</p>
		</div>

		<h1>
			<a href="#" onclick="history.back()"; return false;><font color="FFFFFF">back</font></a>
			<font color="FF7A7A">.</font>
		</h1>

	</center>
	<br>
	<br>
</body>
</html>