<!DOCTYPE html>
<html>
<head>
	<meta name="viewpoint" content="width=device-width, initial-scale=1.0">
	<meta property="og:title" content="It Is Easier to Spend Money Than to Change Behaviour"/>
	<meta property="og:url" content="https://siu2lh.com/articles/it-is-easier-to-spend-money-than-to-change-behaviour.html"/>
	<style>
		body {
			background-color: #000000;
		}
		h1 {color: #000000;}
		p {
			color: #FFFFFF;
			font-family: "Georgia";
		}

		a:link {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}
		
		a:visited {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}

		a:hover {
			color: #00FFFF;
			background-color: transparent;
			text-decoration: none;
		}

		.h1_recentangle {
			height: 80px;
			width: 100%;
			background-color: #000000;
			text-align: center;
			justify-content: center;
			align-items: center;
			display: flex;
			margin: 0;
		}

		.post_window {
			height: 80%;
			width: 50%;
			background-color: #000000;
			border: solid 2px #FFFFFF;
			padding: 50px;
			text-align: justify;
			text-justify: inter-word;
			align-items: center;
			display: flex;
			transition: width 0.5s, height 0.5s;
			box-shadow: 0 0 2px #FFFFFF;
		}

		.post-title {
			font-weight: bold;
			font-size: 24px;
			font-family: "Georgia";
		}

	</style>
	<title>It Is Easier to Spend Money Than to Change Behaviour</title>
	<link rel="icon" type="image/x-icon" href="images/favicon.png">
</head>

<body>
	<a href="https://www.siu2lh.com">
		<div class="h1_recentangle">
			<h1>
				<font color="FF7A7A">.</font>
			</h1>
		</div>
	</a>
	<br>
	<center>

		<div class="post_window">
			<p>
				<span class="post-title">It Is Easier to Spend Money Than to Change Behaviour</span>
				<br>
				<br>
				I recently had the pleasure of talking to James Healy about AI and behavioural science, and a little to my surprise, we ended up spending most of our time talking about bullshit and why organisations are full of it. <a href="https://open.spotify.com/show/5DnTKoyOk9HWSDuCnHN8a5">The podcast</a> has not come out yet, but when I do, the link will be here. In the discussion, I probably go into some ideas which at least feel sensible to me, even if I would never defend them as 'results' or 'empirical findings.' The first is that AI is more easily applied to bullshit than to actual, worthwhile tasks. The second is that the value of AI is it allows managers to avoid having to change their behaviour. This post will focus more on the latter, with the former being a bit of a primer. But both, ultimately, speak to the <i>wastefulness</i> of AI, and--I think--the essential failure of modern management education.
				<br>
				<br>
				<b>~~~</b>
				<br>
				By bullshit, I mean things that do not need to be done, or which <a href="https://www.sciencedirect.com/science/article/pii/S0148296324006325">do not contribute anything to the actual productive tasks</a> which the organisation does. This is related to, but not exactly the same as, Graeber's notion of <a href="https://en.wikipedia.org/wiki/Bullshit_Jobs">bullshit jobs</a> (bullshit jobs are defined subjectively, as in do <i>you</i> feel your job contributes nothing, whereas I am trying to define bullshit a bit more 'objectively,' as in, if the task were to be eliminated, would the profit or loss go up or down?). Bullshit comes from somewhere. While someone like Veblen would point to <a href="https://archive.org/details/onnatureusesofsa0000vebl">sabotage</a> by people in the organisation--and no doubt sabotage takes place, in some instances--I prefer to understand bullshit creation (or proliferation) in two ways. The first is through bounded rationality. The second is through power dynamics, or what I might call managerial authoritarianism, and I will come back to this.
				<br>
				<br>
				You can read most of the bounded rationality perspective <a href="https://www.sciencedirect.com/science/article/pii/S0148296324006325">here</a>, but I will summarise for the sake of this post (it is also in the podcast). We each have limited cognitive capacities. A manager, whose job is to manage the interests and desires of an organisation's different stakeholders, can rarely pay attention to <i>every</i> stakeholder. The workers are striking for a pay rise. The shareholders are demanding a larger dividend. And a junior manager is trying to hire a personal hype-person who will "improve team morale and drive growth in excellence," or some bollocks like that. You and I can see where the bullshit is coming from here, but the senior manager in the middle of it all has more important things to deal with--strikes and shareholder revolts--and so yes, the personal hype-person is hired, perhaps at great and ongoing expense, and bullshit has been created.
				<br>
				<br>
				My instinct is that everything AI can do well--and I will generally be referring to <i>generative</i> AI when I say AI--is of the bullshit variety. This is because no one cares if bullshit is done well. No one cares what a report <i>actually</i> says, if no one is going to read it. Or, to go a layer deeper, no one cares if the <i>summary</i> of the report is inaccurate, or lacking in meaningful detail, if the report itself--perhaps generated with AI--is also irrelevant to decision-making. No one cares if an AI transcription of a meeting is wrong, if details are missing or fabricated, and so on, if no one wants to go to the meeting, if the meeting's attendees all think it is a waste of time, if no one was ever going to read the transcription, and so on. And no one cares if your complaints chatbot pisses your customers off--they're already pissed.
				<br>
				<br>
				In part, my reasoning for why AI is readily applied to bullshit is because AI is unreliable. But the tasks where unreliability does not matter are those which are, often, bullshit. Bullshit is thus the domain that a company can show off its 'cutting-edge,' 'forward-thinking,' 'AI-driven' approach to business, without, you know, actually risking the integrity of the core activities which keep the lights on. Now, this is conjecture, or my hypothesis--I am not claiming this is something I have divined as a professional smart person. I am also quite sure that I will be forcefully told I am wrong, publicly or privately, by people who have 'AI expert' in their LinkedIn bio, and so on. But I will offer something which might be approaching evidence. If one were to read about the <a href="https://www.wsj.com/tech/ai/early-adopters-of-microsofts-ai-bot-wonder-if-its-worth-the-money-2e74e3a2">trials of Microsoft's Copilot AI system</a>--a generative AI system which integrated into the Microsoft <i>Office</i> suite of products, one finds that Copilot was well-received for users of PowerPoint. I can sympathise with a dislike of having to make PowerPoint presentations, and so I can understand why a generative AI system might be worthwhile here, from the perspective of the person <i>having</i> to make the PowerPoint (I will return to this, too). But Copilot was allowed nowhere near Excel. You know, that computer program all the accountants use, the one which produces the documents for which it is <i>criminally important</i> they be accurate.
				<br>
				<br>
				Here's the thing, and I think the key thing that all AI sceptics in this neck of the woods emphasise, and all the 'AI expert' LinkedIn bio types fail to notice: <i>It does not matter whether AI can perform a task, what matters is whether that task needs to be performed.</i> If you are in the business of selling AI, I can understand why this truism is convenient to ignore. But if you run a business, or any organisation, and actually want to make your business more successful, this truism cannot be ignored. Indeed, investigating the nature of the tasks to which AI can be applied becomes <i>the</i> essential 'AI innovation' task. And my instinct (again, maybe I am wrong) is the unreliability of these systems mean they are best applied to things that do not matter. To bullshit.
				<br>
				<br>
				<b>~~~</b>
				<br>
				The second source of bullshit is what I will call <i>managerial authoritarianism</i>. The name is quite straightforward, but for avoidance of doubt, this is what I mean. Most organisations are authoritarian. You have a boss, and you do what your boss says. If you do not, you suffer some consequences. The slight inflection I would place on this--the managerial part--is that in many instances, there is probably no compelling reason why your boss is actually your boss. Their authority does not stem from their inherent superiority--be it knowledge, leadership, conquest, and so on. As <a href="https://allpoetry.com/Questions-From-A-Worker-Who-Reads">Brecht writes</a>, "The young Alexander conquered India--<i>was he alone?</i>" This is to say, the authority in the authoritarianism will, in many cases, emerge <i>entirely</i> because of the rank that a person holds within the organisation. This is important, I think, because when one's authority, or specialness, is entirely derived from one's hierarchical position, the exercise of authority, as a defence of that hierarchy, becomes an end in itself. You get your subordinates to jump, not to see how high they can get, but to remind them that you can make them do it.
				<br>
				<br>
				Graeber writes quite a bit about this (in <a href="https://en.wikipedia.org/wiki/Bullshit_Jobs"><i>Bullshit Jobs</i></a> but also in his better, less read work, <a href="https://en.wikipedia.org/wiki/The_Utopia_of_Rules"><i>The Utopia of Rules</i></a>). He talks about how some bullshit jobs take the form of goons, essentially those people who are hired to serve as transmission vectors for a more senior person's authority. He also talks about lackeys, people who are the modern managerial equivalent of building the pyramids of Giza--they exist to show off how important you are. These are fine <i>origins</i> of bullshit--as above, managerial authoritarianism does create bullshit, just as bounded rationality does. But I think managerial authoritarianism is more important as an explanation why for bullshit persists, despite <i>everyone</i> knowing it exists, and for why AI is being applied to perform bullshit, despite <i>everyone</i>, in their hearts, knowing this to be the case.
				<br>
				<br>
				Here's my thesis, or tweet, or 10 second TED talk soundbite: it is easier to spend money than to change behaviour. People who study behaviour change, broadly, will readily admit that behaviour change is hard (though I often think this is a cynical move, because they will then say something like 'but my neat trick can do it,' and of course, if behaviour change is hard, that one neat trick becomes valuable). The question is, <i>why</i> is behaviour change hard? And part of the answer, I think, must be the retort: <i>is it?</i> People change their behaviour all the time. They choose to watch a new TV show, to try a new restaurant. I am constantly amazed at the willingness and enthusiasm of people to try new activities, from life painting to extreme sports. I regularly meet people who will cycle to work one day a week, and catch the train the next. Millions of people took, quite enthusiastically, to work-from-home requirements during the pandemic, and <a href="https://archive.ph/fDf7L">this continues</a>. When Obamacare was rolled out in the US, hundreds of thousands of people were keen to 'change their behaviour' and sign up for health insurance--so many, in fact, that <a href="https://www.reuters.com/article/business/healthcare-pharmaceuticals/days-before-launch-obamacare-website-failed-to-handle-even-500-users-idUSBRE9AL03L/">the website crashed</a>.
				<br>
				<br>
				Of course, one might say these are all innoculous things--watching a different TV show is not 'behaviour change' because you are still watching TV, and so on (a pretty lame criticism that reveals 'behaviour change' does not actually mean anything). But this misses the point. Behaviour change is only hard when people do not <i>want</i> to change their behaviour. Yes, some behavioural scientist will chime up and say, 'well, actually, behavioural biases often prevent people from doing want they already <i>want</i> to do,' but this comment more often than not has the effect of obscuring the commonsense result that behaviour change is easy (or, at least, <i>easier</i>) when people <i>want</i> to change their behaviour. (Two notes on the behavioural science argument: a) the literature is notoriously bad for actually demonstrating that people fail to do want they already want to do. It is stated in <a href="https://en.wikipedia.org/wiki/Nudge_(book)"><i>Nudge</i></a>, but not hugely evidenced, and it is an essentially absent feature from the literature to this day. This is a major gap in behavioural science which we do not talk about; b) the recourse to behavioural biases conveniently ignores that their may be many reasons why people fail to do what they already want to. For instance, they might not have the money, or they might have an authoritarian boss forcing them to do something. Behavioural scientists typically ignore these situations, because tackling them requires behaviour change infused more so with a sense of <i>politics</i> than with the aesthetics of science, in my opinion.)
				<br>
				<br>
				Back to bullshit, and managerial authoritarianism. Lots of bullshit can be eliminated from organisations by senior managers changing their behaviour so as to not invent it in the first place. Let us go back to PowerPoints, the thing I actually sympathised with. Presentations that matter are those a presenter wants to spend a lot of time working on. They want to write and design the presentation themselves. They want to know it inside and out. Yes, AI might help them quickly whip up a prototype, but I am confident that the time-savings on this would actually be very small, as an important presentation requires a huge amount of practice and tweaking in an iterative fashion. I would never present an AI generated lecture, not because the AI might do a bad job (I think it would), but because I <i>need</i> to know the lecture on a deep level to do a good job. Presentations that matter take time, and require deep engagement. Otherwise, they will be bad. Presentations that do not matter do not require these things. They are bullshit, and so no one cares if they are bad. Now, why might a person be required to give a bad presentation? Often, because their manager <i>wants</i> some presentation to be given. This logic, I think, can be applied to many of the bullshit tasks anyone who has worked in an organisation encounters. The endless report writing is often to make their manager <i>feel</i> more informed. Performance reviews are often so a manager can <i>feel</i> in control. So much bullshit within modern organisations is, in my opinion, a product of managerial authoritarianism because a) the exercise of authority is the end in of itself; and b) managers are insecure about themselves, and so use bullshit to create a sense of security.
				<br>
				<br>
				I am hesitant to try and psychoanalysis a whole class of people in post-industrial society. I am confident some managers are fantastic, and occupy their positions because of genuine skill and insight. But I am also confident that these managers, secure in their position, assured of their authority because they are <i>authorities</i>, do not create bullshit. These are not the people whose behaviour needs to change. Those managers who create bullshit need to change their behaviour. Chiefly, I think, they need to trust people--most bullshit seems to be an exercise in controlling people's time and minds to reduce the dangers which come from more autonomous behaviour. But trust is a dangerous thing. It conveys accountability. If you trust someone, and they break your trust, you will be accountable for the consequences. That can be scary, especially if you--in your heart--doubt your own abilities, your own right to hold authority (as I suspect many managers do). This is a point Dan Davies has made, quite well, in his book <a href="https://en.wikipedia.org/wiki/The_Unaccountability_Machine"><i>The Unaccountability Machine</i></a>.
				<br>
				<br>
				Managers who suffer from managerial authoritarianism do not <i>want</i> to change their behaviour. This is why bullshit persists, in some instances. But, to go back to my soundbite, it is not simply that managers do not want to change their behaviour. In many instances, they have an easier 'solution' to the problem of organisational efficiency--they can spend money. This, fundamentally, is a big component of the 'AI efficiency drive,' in my opinion. Managers who do not want to trust their workers; who, perhaps, do not want to give up some of their power; and who, it should be said, would find it terribly embarassing to admit they have been creating bullshit, receive a 'get out of jail free card' with AI. AI enables a narrative, told a thousand times by now, of transforming organisations by unlocking new efficiencies, freeing workers to be more productive, streamlining processes, so on and so forth. And so, what would you do? Would you admit to a whole load of bullshit, and change your management style to free your workers from bullshit activities, trusting them with their newfound time to deliver greater efficiencies, while at the same time demonstrating your own vulnerabilities as an authority in the organisation? Or would you spend a bunch of money on a technology that claims your organisation will become super-efficient without you, the manager, really having to change what you do? Everyone wants to have their cake and eat it.
				<br>
				<br>
				<b>~~~</b>
				<br>
				If you think I am criticising AI here, I think you are missing the point. As with all technology, it does not matter what AI does, it matters how we use it. And, for the reasons laid out above, I think AI is being used in ways which are inefficient, and which reflect non-technical challenges which our modern economies need to address, rather than technical ones. I believe the failure of AI, as with the computer and other information technologies, is majorly a failure of management education, and a failure of the modern political economy.
				<br>
				<br>
				Here is another TED talk soundbite: radically transformative technologies should radically transform organisations. AI is not doing this. It is <i>changing</i> things. Some people are <a href="https://www.ft.com/content/9e66ba5b-5403-4e82-b26b-8d72aadf95d4">losing their jobs</a>. Others are likely <a href="https://www.ft.com/content/271c5f5f-2dad-4a35-a1cc-83a4a1b7ad6d">seeing their jobs transformed</a>. New <a href="https://theconversation.com/ai-is-a-multi-billion-dollar-industry-its-underpinned-by-an-invisible-and-exploited-workforce-240568">industries are popping up</a>, for better or worse. But your boss is still your boss, right? Decisions about what tasks you do, and <i>how</i> you do them, are still largely in the hands of someone else, right? The hierarchy of organisation--one we have had for two hundred years, and maybe longer if the Catholic Church has anything to say about it--is still here. Is that not <i>strange</i>? Or, to put it differently, is it not odd that the only time in recent memory that organisations have actually been (somewhat) radically transformed is during the pandemic, during an event that no manager, executive, or shareholder had any influence over? <i>Is that not strange</i>?
		</div>

		<h1>
			<a href="https://www.siu2lh.com"><font color="FFFFFF">back</font></a>
			<font color="FF7A7A">.</font>
		</h1>

	</center>
	<br>
	<br>
</body>
</html>