<!DOCTYPE html>
<html>
<head>
	<meta name="viewpoint" content="width=device-width, initial-scale=1.0">
	<meta property="og:title" content="Empowering Everyday Experts"/>
	<meta property="og:url" content="https://siu2lh.com/articles/empowering-everyday-experts.html"/>
	<style>
		body {
			background-color: #000000;
		}
		h1 {color: #000000;}
		p {
			color: #FFFFFF;
			font-family: "Georgia";
		}

		a:link {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}
		
		a:visited {
			color: #FF7A7A;
			background-color: transparent;
			text-decoration: none;
		}

		a:hover {
			color: #00FFFF;
			background-color: transparent;
			text-decoration: none;
		}

		.h1_recentangle {
			height: 80px;
			width: 100%;
			background-color: #000000;
			text-align: center;
			justify-content: center;
			align-items: center;
			display: flex;
			margin: 0;
		}

		.post_window {
			height: 80%;
			width: 50%;
			background-color: #000000;
			border: solid 2px #FFFFFF;
			padding: 50px;
			text-align: justify;
			text-justify: inter-word;
			align-items: center;
			display: flex;
			transition: width 0.5s, height 0.5s;
			box-shadow: 0 0 2px #FFFFFF;
		}

		.post-title {
			font-weight: bold;
			font-size: 24px;
			font-family: "Georgia";
		}

	</style>
	<title>Empowering Everyday Experts</title>
	<link rel="icon" type="image/x-icon" href="images/favicon.png">
</head>

<body>
	<a href="https://www.siu2lh.com">
		<div class="h1_recentangle">
			<h1>
				<font color="FF7A7A">.</font>
			</h1>
		</div>
	</a>
	<br>
	<center>

		<div class="post_window">
			<p>
				<span class="post-title">Empowering Everyday Experts</span>
				<br>
				<br>
				<i>The following essay is my shortlisted (though, unfortunately not winning) essay for the <a href="https://twitter.com/BennettInst/status/1763237506160402533">Bennett Institute for Public Policy Prize 2024</a>. It is mostly an expanded version of <a href="were-probably-using-ai-wrong.html">this post</a> I made in late 2023. This version of the essay was published on my Substack in March 2024.</i>
				<br>
				<br>
				<b>Introduction</b>
				<br>
				My first job after university was as an analyst for a large organisation in Manchester. The organisation was introducing a new finance system, and it was not going well. Many employees did not understand how the system worked. They were causing errors, and I had to fix them. Unfortunately, the errors never stopped. So, I decided to investigate the problem myself.
				<br>
				<br>
				I started by asking my fellow employees what they did not understand about the system. The usual culprits of resisting change and a lack of training came up. Yet, I realised these were more <i>symptoms</i> of a problem, rather than causes.
				<br>
				<br>
				In chatting, I learned the new system was being introduced for one reason. Or, more specifically, <i>one person</i>. Every month, the finance director demanded a one-thousand-page summary of the organisation's financials. This report took the finance team around two-weeks to produce. The new system, supposedly, would produce the report in a single click.
				<br>
				<br>
				Obviously, the directors thought the new system was a no-brainer. After all, it would <i>double</i> productivity. But to me, it was <i>the crucial error</i> to be solved. There was no world in which anyone was reading this report every month. Much less, using the information contained within to make worthwhile decisions. The report was wasting employees' time. And with the introduction of the new system, wasting tens of millions of pounds, too. The solution, to me, was simple: fire the finance director.
				<br>
				<br>
				Unsurprisingly, this suggestion was ignored.
				<br>
				<br>
				I left this job to return to university, where I came to some relevant conclusions. Firstly, that most organisations are inefficient. Secondly, that few understand why. Thirdly, that technology can help. But, fourthly, that it often does not. Over the years, I have collected stories like my own experience. In teaching policymakers and business executives, I have discovered those with similar experiences. And with advances in AI, I believe these ideas are increasingly important.
				<br>
				<br>
				In this essay, I argue AI can improve public services by empowering the everyday experts who deliver them--our public servants. This doesn’t mean using AI to analyse or generate more <i>information</i>. Today, many of the problems organisations face are because of <i>too much information</i>. This means decision-makers often struggle to access the <i>right information</i>. Using AI to get the right information to the right people will allow us to unlock more of the talent in our public services. And our services will benefit, as a result.
				<br>
				<br>
				Yet, to arrive at this argument, I must slay a dragon: the belief that more information is always better. To do so, we must understand how teleprinters work. We must learn lessons from city planning. And we must learn how to tell if a baby is healthy. Doing so, I hope to convince you that when someone knows what they're doing, <i>most things can be ignored</i>.
				<br>
				<br>
				<b>Solving Prolems Without Solutions</b>
				<br>
				We live in an era of big data. Smartphones track innumerable aspects of our everyday lives. Meanwhile, satellite systems track our planet’s weather <i>every day</i>. Digital information is the thread which binds the modern world together.
				<br>
				<br>
				Without information, modern AI would be impossible(<a href="http://aima.cs.berkeley.edu/">Russell and Norvig, 2009</a>). Consider a classic computer science problem, natural language processing. The question at the heart of this problem is: how can a computer understand the meaning of words? It is quite easy to tell a computer that a word exists. But think of the word 'cat.' Most likely, a cloud of associations--images, emotions, memories--popped into your head. These associations capture the semantic meaning of the word 'cat.' Philosophers might call it the cat's <i>essence</i>. Yet, these associations are very difficult to describe. As such, it is difficult to teach it to a computer (<a href="https://direct.mit.edu/books/monograph/3132/PerceptronsAn-Introduction-to-Computational">Minsky and Papert, 2017</a>).
				<br>
				<br>
				Modern AI solves this problem with data. Given enough data, an AI can calculate which words are often used together (<a href="https://arxiv.org/pdf/1301.3781.pdf">Mikolov <i>et al</i>., 2013</a>). Then, by mimicking these patterns, it can <i>appear</i> to understand their semantic meaning. This is what large language models like ChatGPT do (<a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">Wolfram, 2023</a>). The key to this is a powerful idea: that with enough data, we can solve problems without knowing the solution (<a href="https://www.versobooks.com/en-gb/products/816-revolutionary-mathematics?_pos=3&_sid=febee61de&_ss=r">Joque, 2022</a>).
				<br>
				<br>
				Recommendation algorithms, targeted ads, and prediction models all rely on this idea. Older AI systems, known as symbolic AI, did not. Symbolic AI approaches gave computers general rules to solve a variety of problems. But most of what interests humans--like cats--cannot be adequately defined using a series of rules. As one joke goes, a barman asks a customer what a chair is. The customer responds, “it has four legs, and you can sit on it.” The barman guffaws: “I don’t see any horses in here!”
				<br>
				<br>
				Solving problems without knowing solutions has revolutionised AI. The idea is the bedrock of our modern information society. But it requires a lot of data. Today, scholars and engineers boast of ever-larger models and ever-more variables. Some even speculate about a world of 'N = <i>all</i>'--a world where everyone is in the dataset (<a href="https://doi.org/10.1177/2053951716631130">Kitchin and McArdle, 2016</a>). As one business leader once told me at a forum on AI: <i>more is better, all is best</i>.
				<br>
				<br>
				<b>More Is Better, All Is Best</b>
				<br>
				<i>More is better, all is best</i> is not an AI innovation. It is human psychology. Peter Drucker observes that organisations always desire more information (<a href="https://www.taylorfrancis.com/books/mono/10.4324/9780080549354/effective-executive-peter-drucker">Drucker, 2006</a>). This is especially true when people must make (or delay) difficult decisions. In everyday life, we like information, too. Humans dislike ambiguity and uncertainty (<a href="https://www.jstor.org/stable/1884324?seq=1">Ellsberg, 1961</a>). More information can make us feel more comfortable. And when mistakes arise, a lack of information is almost always blamed as a culprit.
				<br>
				<br>
				Recent AI innovations play on our instinctive desire for more information. Generative AI is an obvious example. It allows a HR department to draft dozens of job descriptions. It enables a PR department to play with dozens of press releases. It can generate innumerable images, videos, and PowerPoint presentations, all in an afternoon. Policymakers can generate public information posters. For every town. For every age group. For every day of the week. With generative AI, you can have any colour you want, including <i>all of them</i>.
				<br>
				<br>
				Less eye-catching, though still important, is the role of AI as a data analysis tool. Large organisations--particularly in the public sector--dedicate many resources to data management. Figuring out what to do next requires expensive data scientists and policy analysts. If the organisation wants to analyse more data, it has rarely come cheap. But modern AI can easily scale to analyse as much data as one would like (<a href="https://www.nature.com/articles/nature14539">LeCun, Bengio and Hinton, 2015</a>). It may not know as much as those experts it does the work of. But if the answer is somewhere in the data that might not matter. Data analysis is becoming <i>commodified</i> (<a href="https://journals.sagepub.com/doi/pdf/10.1057/jit.2015.5">Zuboff, 2015</a>). And the cost savings are rarely lost on fiscally minded politicians.
				<br>
				<br>
				With modern AI, it is easier than ever to satisfy the <i>more is better, all is best</i> urge that many organisations have. But while AI proliferates information cheaply, it also risks creating a lot of waste. Firstly, money may be wasted on unnecessary data, rather than helping cash-strapped public services. Secondly, AI may be wasted on analysing unhelpful data, rather than supporting public services. To appreciate these sources of waste, let’s start with a look at city planning.
				<br>
				<br>
				<b>How Not to Build a Highway</b>
				<br>
				Congestion is an important consideration in modern city planning. It slows down the flow of goods, annoys drivers, and worsens air quality. Congestion is bad. But solving congestion is not easy. One idea which occurs to most people is to expand the roads so there is more car capacity. Unfortunately, evidence shows this instead makes congestion worse (<a href="https://www.aeaweb.org/articles?id=10.1257/aer.101.6.2616">Duranton and Turner, 2011</a>). Adding capacity encourages more people to drive. Often, in fact, it encourages more people to drive than the expanded road can handle. And so, congestion returns.
				<br>
				<br>
				In economics, we call this phenomenon Jevons’ paradox. In the 1860s, more efficient coal furnaces lead people to predict demand for coal to fall. But William Stanley Jevons observed demand actually <i>increased</i>. The more efficient furnace allowed manufacturers to lower the prices of their goods. This increased demand for these goods, and thus demand for manufacturing inputs, like coal (<a href="https://www.inist.org/library/1865.Jevons.The_Coal_Question.Macmillan.pdf">Jevons, 1866</a>).
				<br>
				<br>
				Jevons' paradox is likely true of AI. When used for analysis, AI is reducing the costs of analysing more information. Though, not the costs of <i>collecting</i> information. When used generatively, AI is reducing the costs of proliferating information. Though, not the costs of <i>navigating</i> information. Both uses are seeing sizeable demand, and rapid adoption (<a href="https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference">Porter, 2023</a>). Rather than analysing existing data for a lower cost, organisations are starting to collect more data (<a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862">Srnicek, 2016</a>). Rather than refining the options that decision-makers must navigate, organisations are generating more options. AI can do many things, but the belief in <i>more is better, all is best</i> means reducing current costs is unlikely one of them.
				<br>
				<br>
				Regardless, AI may still produce substantial benefits. Jevons observed prices falling, output rising, and technology becoming more efficient. AI may allow us to identify previously hidden insights in our public services. Public services will still benefit, provided these new insights outweigh heightened costs. For instance, data collection costs.
				<br>
				<br>
				But as the problem of congestion shows, Jevons' paradox isn't always good. We can collect more data because AI makes it cheap to analyse. We can explore more ideas because AI makes them cheap to generate. But collecting more data, and sifting through more generative outputs, costs money. This will be a waste if the extra data or additional ideas produce no new insights. Again, there may be valuable insights! But any successful organisation probably already does most things pretty well. Thus, rather than letting AI satisfy the urge of <i>more is better, all is best</i>, we should ask a simple question. <i>Will more information lead to better decisions?</i> If the answer is no, acting as if it is yes will just waste of money.
				<br>
				<br>
				<b>Most Things Can Be Ignored</b>
				<br>
				It will also waste the AI technology. Consider two examples.
				<br>
				<br>
				One of the fathers of AI, Herbert Simon, tells a story about a U.S. diplomatic office in the 1960s (<a href="https://mitpress.mit.edu/9780262691918/the-sciences-of-the-artificial/">Simon, 1981</a>). The office received important communications via telegrams. Telegrams were then printed using teleprinters, and printouts given to decision-makers. But there was a problem. During a diplomatic crisis, telegrams would swamp the office. The teleprinters could only print so fast, trapping important information in a backlog. By the time the information reached decision-makers, it was significantly less useful. The office, <i>naturally</i>, bought more teleprinters. But the problem soon returned. They could print more, so they received more. <i>Classic Jevons' paradox</i>. Simon's solution was simple, and radical. He pointed out that most of information printed was never used by decision-makers. The office could eliminate the backlog, with fewer teleprinters, if they only printed what was necessary.
				<br>
				<br>
				Back to Drucker. He tells the story of Robert McNamara's time in the Department of Defense (DoD; <a href="https://www.taylorfrancis.com/books/mono/10.4324/9780080549354/effective-executive-peter-drucker">Drucker, 2006</a>). A big problem facing McNamara was the U.S. military budget. Procurement costs were spiralling out of control. This wasn't just an effect of the Cold War. The army required tens of thousands of unique items. Supplying them was a complicated, and thus expensive, task. The DoD had commissioned several studies to understand the issue. Reports inches thick described how the army acquired each item. Yet, despite more information, costs continued to spiral. McNamara's solution was simple, and radical. He asked his staff to order every item by its contribution to the total cost. When this showed 4% of items accounted for 90% of costs, he told his team to ignore the other 96%. Costs soon came under control.
				<br>
				<br>
				I love these stories. My story about the finance director falls into the same genre. They show that organisations often assume problems arise from a lack of information. But often, too much information prevents a solution from appearing. Using AI, or other technologies, to proliferate information will further bury solutions. And, perhaps worse, we will waste transformative technologies patching up bad organisational systems.
				<br>
				<br>
				<b>Empowering Everyday Experts</b>
				<br>
				However, in each story, one still needs to figure out what information to ignore. This is where AI can make a great contribution to public services.
				<br>
				<br>
				In the 1980s, Herbert Simon again popped up. This time, he argued we should use AI in conjunction with expert judgement (<a href="https://doi.org/10.1287/inte.17.4.8">Simon, 1987a</a>). Nurses, doctors, teachers, and others are everyday experts. They know a huge amount about services which impact everyone's life. Simon pointed out that everyday experts often have fantastic intuitions (<a href="https://www.jstor.org/stable/4164720">Simon, 1987b</a>). Experts can make very good, quick, decisions when given the right information. For instance, take the Apgar test. Developed by paediatric specialists, this test quickly assesses the health of newly-borns. Rather than running a bunch of tests, a nurse checks five physical vitals. They give each vital a score from 0 to 2. If the total score is more than 7, the baby is probably in good health (<a href="https://journals.lww.com/anesthesia-analgesia/Fulltext/2015/05000/Dr__Virginia_Apgar_and_the_Apgar_Score__How_the.23.aspx">Calmes, 2015</a>).
				<br>
				<br>
				There are two issues with everyday expertise. Firstly, most experts aren't conscious of how they make decisions. Chess grandmasters do not consciously analyse each piece; they just know broad positions. Figuring out how everyday experts work their magic, then, is difficult. Secondly, experts can make mistakes when over-faced with unnecessary information. Show a chess grandmaster a board state that would never occur in a game, and they'll struggle to find the best move. In the era of big data, experts must spend more and more time blocking out noise which others think are signals (<a href="https://mitpress.mit.edu/9780262691918/the-sciences-of-the-artificial/">Simon, 1981</a>).
				<br>
				<br>
				Simon proposed to use AI as an expert support system to solve these problems (<a href="https://doi.org/10.1287/inte.17.4.8">Simon, 1987a</a>). By comparing expert decisions to available information, AI can learn which information matters. Then, AI can filter out the noise, leaving everyday experts with the <i>right</i> information. In some areas of public service, this use of AI is already happening. For instance, there is a lot of public health research. Too much, in fact, for policymakers to ever read, let alone synthesise. Recently, researchers have built an AI system trained on all this health research (<a href="https://doi.org/10.1093/abm/kaaa095">Aonghusa and Miche, 2020</a>). Policymakers can then specify policy relevant details. For instance, the setting of the policy intervention. Then, the AI suggests a range of approaches. This includes estimates of each approach's likelihood of success. Expert policymakers then decide what to do. What matters here is not that AI analyses <i>more</i> information. Rather, that it acts as a tool to sift through the excess that experts already face, allowing them to focus on the decisions that matter.
				<br>
				<br>
				By empowering everyday experts with AI, we can improve our public services. It would give our public servants the tools they need to do what they do best. It would reaffirm our trust and pride in their expertise. And it would keep our public servants in control of the AI, rather than letting an AI direct them. Thus, it enshrines public service accountability.
				<br>
				<br>
				AI is impressive. It creates opportunities that, only recently, few imagined. But there is a huge amount of talent within our public services. Using AI to empower these everyday experts is essential. While the potential for AI to expand the information available to us is interesting, it is not a panacea. Sometimes, we will discover valuable insights. Often, though, we'll waste money and technology. The answer to the question '<i>how can AI be implemented to improve public services?</i>' is simple, but radical.
			</p>
		</div>

		<h1>
			<a href="https://www.siu2lh.com"><font color="FFFFFF">back</font></a>
			<font color="FF7A7A">.</font>
		</h1>
		
	</center>
	<br>
	<br>
</body>
</html>